# -*- coding: utf-8 -*-
"""
Video Player Widget - Supports ecamera/fcamera (HEVC via PyAV) and qcamera (H.264 via OpenCV)
å½±ç‰‡æ’­æ”¾å™¨å…ƒä»¶ - æ”¯æ´ä¸‰ç¨®ç›¸æ©Ÿæ ¼å¼
"""
from PyQt6.QtWidgets import (
    QWidget, QVBoxLayout, QHBoxLayout, QPushButton, QLabel,
    QSlider, QComboBox, QSizePolicy
)
from PyQt6.QtCore import Qt, QTimer, pyqtSignal
from PyQt6.QtGui import QImage, QPixmap
import logging
from pathlib import Path
from datetime import datetime
from typing import Optional
import numpy as np

# Video decoding imports
try:
    import av  # PyAV for HEVC
    PYAV_AVAILABLE = True
except ImportError:
    PYAV_AVAILABLE = False
    logging.warning("PyAV not available, HEVC videos won't play")

try:
    import cv2  # OpenCV for H.264/TS
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    logging.warning("OpenCV not available, H.264 videos won't play")

# ä¸å†éœ€è¦ Cap'n Proto - å¹€æ™‚é–“æˆ³è¨˜å·²å­˜åœ¨è³‡æ–™åº«ä¸­

logger = logging.getLogger(__name__)


class VideoPlayer(QWidget):
    """
    å½±ç‰‡æ’­æ”¾å™¨ Widget

    æ”¯æ´:
    - ecamera: HEVC (PyAV)
    - fcamera: HEVC (PyAV)
    - qcamera: H.264/TS (OpenCV)
    """

    # Signals
    time_changed = pyqtSignal('qint64')  # Current time (ns) - ä½¿ç”¨ 64 ä½å…ƒæ•´æ•¸é¿å…æº¢ä½
    frame_changed = pyqtSignal(int)  # Current frame index
    playing_state_changed = pyqtSignal(bool)  # Playing state (True=playing, False=paused)

    def __init__(self, parent=None, db_manager=None, translation_manager=None):
        super().__init__(parent)

        # Database manager (ç”¨æ–¼è®€å–å¹€æ™‚é–“æˆ³è¨˜)
        self.db_manager = db_manager

        # Translation manager
        self.translation_manager = translation_manager

        # Video state
        self.camera_paths = {}  # {camera_name: path}
        self.current_camera = None
        self.frames = []  # Preloaded frames
        self.current_frame_idx = 0
        self.fps = 20.0
        self.is_playing = False
        self.sync_mode = True  # åŒæ­¥æ¨¡å¼ï¼šç­‰å¾…è³‡æ–™æŸ¥è©¢å®Œæˆæ‰é€²å…¥ä¸‹ä¸€å¹€

        # Time synchronization
        self.start_time_ns = 0
        self.wall_time_offset = 0
        self.segment_start_timestamp = None  # Segment çš„æ­£ç¢ºèµ·å§‹æ™‚é–“ï¼ˆUnix timestamp ç§’ï¼Œå¾ GPS æ¨ç®—ï¼‰
        self.segment_num = 0  # Segment ç·¨è™Ÿ
        self.segment_id = None  # Segment IDï¼ˆå¾è³‡æ–™åº«æŸ¥è©¢å¹€æ™‚é–“æˆ³è¨˜ç”¨ï¼‰
        self.frame_timestamps = []  # æ¯ä¸€å¹€çš„å¯¦éš›æ™‚é–“æˆ³è¨˜ï¼ˆå¾è³‡æ–™åº«è®€å–ï¼‰
        self.rlog_path = None  # rlog æª”æ¡ˆè·¯å¾‘ï¼ˆä¿ç•™ä»¥ç›¸å®¹æ€§ï¼Œä½†ä¸å†ç”¨æ–¼è®€å– EncodeIndexï¼‰

        # Playback timer
        self.timer = QTimer()
        self.timer.timeout.connect(self.on_timer_tick)

        self.setup_ui()

    def setup_ui(self):
        """å»ºç«‹ UI"""
        layout = QVBoxLayout(self)
        layout.setContentsMargins(5, 5, 5, 5)

        # Get translation function
        t = self.translation_manager.t if self.translation_manager else lambda x: x

        # ============================================================
        # å½±ç‰‡é¡¯ç¤ºå€
        # ============================================================
        self.video_label = QLabel()
        self.video_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.video_label.setStyleSheet("border: 1px solid #CCC; background: #000;")
        self.video_label.setMinimumHeight(150)
        self.video_label.setSizePolicy(QSizePolicy.Policy.Expanding, QSizePolicy.Policy.Expanding)
        layout.addWidget(self.video_label)

        # ============================================================
        # æ™‚é–“é¡¯ç¤º
        # ============================================================
        time_layout = QHBoxLayout()
        self.time_label = QLabel(t("Time: --"))
        self.time_label.setStyleSheet("font-family: monospace;")
        time_layout.addWidget(self.time_label)

        self.frame_label = QLabel(t("Frame: 0 / 0"))
        self.frame_label.setStyleSheet("font-family: monospace;")
        time_layout.addWidget(self.frame_label)

        time_layout.addStretch()
        layout.addLayout(time_layout)

        # ============================================================
        # æ™‚é–“è»¸æ»‘æ¡¿
        # ============================================================
        self.timeline_slider = QSlider(Qt.Orientation.Horizontal)
        self.timeline_slider.setMinimum(0)
        self.timeline_slider.setMaximum(0)
        self.timeline_slider.valueChanged.connect(self.on_slider_changed)
        layout.addWidget(self.timeline_slider)

        # ============================================================
        # æ§åˆ¶æŒ‰éˆ•
        # ============================================================
        control_layout = QHBoxLayout()

        # ç›¸æ©Ÿé¸æ“‡
        self.camera_label = QLabel(t("Camera:"))
        control_layout.addWidget(self.camera_label)
        self.camera_combo = QComboBox()
        self.camera_combo.addItems(["ecamera", "fcamera", "qcamera"])
        self.camera_combo.setCurrentText("fcamera")  # é è¨­ä½¿ç”¨ fcamera
        self.camera_combo.currentTextChanged.connect(self.on_camera_changed)
        control_layout.addWidget(self.camera_combo)

        control_layout.addStretch()

        # æ’­æ”¾/æš«åœæŒ‰éˆ•
        self.play_button = QPushButton(t("Play"))
        self.play_button.clicked.connect(self.toggle_play)
        self.play_button.setEnabled(False)
        control_layout.addWidget(self.play_button)

        # å‰ä¸€å¹€
        self.prev_frame_btn = QPushButton(t("â—€ 1 Frame"))
        self.prev_frame_btn.clicked.connect(lambda: self.step_frame(-1))
        control_layout.addWidget(self.prev_frame_btn)

        # å¾Œä¸€å¹€
        self.next_frame_btn = QPushButton(t("1 Frame â–¶"))
        self.next_frame_btn.clicked.connect(lambda: self.step_frame(1))
        control_layout.addWidget(self.next_frame_btn)

        # å¾Œé€€ 5 ç§’
        self.back_5s_btn = QPushButton(t("â—€â—€ 5s"))
        self.back_5s_btn.clicked.connect(lambda: self.step_time(-5.0))
        control_layout.addWidget(self.back_5s_btn)

        # å‰é€² 5 ç§’
        self.forward_5s_btn = QPushButton(t("5s â–¶â–¶"))
        self.forward_5s_btn.clicked.connect(lambda: self.step_time(5.0))
        control_layout.addWidget(self.forward_5s_btn)

        control_layout.addStretch()

        layout.addLayout(control_layout)

    def load_segment(self, db_manager, segment_id: int):
        """
        è¼‰å…¥æŒ‡å®š Segment çš„å½±ç‰‡

        Args:
            db_manager: DatabaseManager instance
            segment_id: Segment ID
        """
        try:
            # å„²å­˜ segment_id å’Œ db_managerï¼ˆç”¨æ–¼è®€å–å¹€æ™‚é–“æˆ³è¨˜ï¼‰
            self.segment_id = segment_id
            self.db_manager = db_manager

            # å–å¾— segment è³‡è¨Š
            segment = db_manager.get_segment_by_id(segment_id)

            if not segment:
                logger.error(f"Segment {segment_id} not found")
                self.video_label.setText(f"Segment {segment_id} not found")
                return

            # å„²å­˜ segment ç·¨è™Ÿï¼ˆæ”¯æ´å…©ç¨®å­—æ®µåï¼‰
            self.segment_num = segment.get('segment_num') or segment.get('segment_number', 0)

            # è¨ˆç®— segment æ™‚é•·ï¼ˆç”¨æ–¼ä¿®æ­£ FPSï¼‰
            segment_start_ns = segment['start_time_ns']
            segment_end_ns = segment['end_time_ns']
            self.segment_duration_sec = (segment_end_ns - segment_start_ns) / 1e9

            # å„²å­˜æ™‚é–“è³‡è¨Š - ä½¿ç”¨å¯¦éš›æ•¸æ“šçš„æ™‚é–“ç¯„åœ
            try:
                # æŸ¥è©¢å¯¦éš›æ•¸æ“šçš„æ™‚é–“ç¯„åœ
                cursor = db_manager.conn.cursor()
                cursor.execute("""
                    SELECT MIN(time_ns)
                    FROM timeseries_data
                    WHERE segment_id = ?
                """, (segment_id,))
                result = cursor.fetchone()
                cursor.close()
                if result and result[0]:
                    self.start_time_ns = result[0]
                    logger.info(f"Using actual data start time: {self.start_time_ns:,} ns")
                else:
                    # æ²’æœ‰æ•¸æ“šæ™‚ä½¿ç”¨ segment çš„æ™‚é–“
                    self.start_time_ns = segment['start_time_ns']
                    logger.warning(f"No data found, using segment start time: {self.start_time_ns:,} ns")
            except Exception as e:
                logger.error(f"Failed to get data start time: {e}")
                self.start_time_ns = segment['start_time_ns']

            self.wall_time_offset = segment['wall_time_offset']

            # å–å¾— route çš„æ­£ç¢ºèµ·å§‹æ™‚é–“ï¼ˆå¾ GPS æ¨ç®—ï¼‰
            try:
                cursor = db_manager.conn.cursor()
                cursor.execute("""
                    SELECT start_timestamp
                    FROM routes
                    WHERE route_id = ?
                """, (segment['route_id'],))
                result = cursor.fetchone()
                cursor.close()
                if result and result[0]:
                    route_start_timestamp = result[0]
                    # è¨ˆç®—æ­¤ segment çš„æ­£ç¢ºèµ·å§‹æ™‚é–“
                    self.segment_start_timestamp = route_start_timestamp + (self.segment_num * 60)
                    logger.info(f"âœ“ Using GPS-based start time: {self.segment_start_timestamp} (route: {route_start_timestamp} + {self.segment_num}Ã—60)")
                else:
                    self.segment_start_timestamp = None
                    logger.warning("âš  Route start_timestamp not set, will use wallTimeNanos (may be inaccurate)")
            except Exception as e:
                logger.error(f"Failed to get route start_timestamp: {e}")
                self.segment_start_timestamp = None

            # å„²å­˜å½±ç‰‡è·¯å¾‘å’Œ rlog è·¯å¾‘
            self.camera_paths = {
                'ecamera': segment.get('ecamera_path'),
                'fcamera': segment.get('fcamera_path'),
                'qcamera': segment.get('qcamera_path')
            }
            self.rlog_path = segment.get('rlog_path')

            logger.info(f"Loaded segment {segment_id} video paths")
            logger.info(f"rlog path: {self.rlog_path}")

            # å…ˆå˜—è©¦è¼‰å…¥ç•¶å‰é¸æ“‡çš„ç›¸æ©Ÿï¼Œå¦‚æœä¸å¯ç”¨å‰‡æŒ‰ç…§ fcamera > ecamera > qcamera é †åºå°‹æ‰¾
            current_camera = self.camera_combo.currentText()
            if self.camera_paths.get(current_camera) and Path(self.camera_paths[current_camera]).exists():
                self.load_video(current_camera)
            else:
                # ç•¶å‰é¸æ“‡ä¸å¯ç”¨ï¼ŒæŒ‰ç…§å„ªå…ˆé †åºå°‹æ‰¾å¯ç”¨çš„ç›¸æ©Ÿ
                for camera in ['fcamera', 'ecamera', 'qcamera']:
                    if self.camera_paths.get(camera) and Path(self.camera_paths[camera]).exists():
                        self.camera_combo.setCurrentText(camera)
                        self.load_video(camera)
                        break

        except Exception as e:
            logger.error(f"Failed to load segment: {e}")
            self.video_label.setText(f"Load failed: {e}")

    def load_video(self, camera: str):
        """
        è¼‰å…¥å½±ç‰‡æª”æ¡ˆä¸¦é è¼‰æ‰€æœ‰å¹€

        Args:
            camera: ç›¸æ©Ÿé¡å‹ ('ecamera', 'fcamera', 'qcamera')
        """
        video_path = self.camera_paths.get(camera)

        if not video_path or not Path(video_path).exists():
            logger.error(f"Video file not found: {video_path}")
            self.video_label.setText(f"æ‰¾ä¸åˆ°å½±ç‰‡æª”æ¡ˆ\n{camera}")
            self.frames = []
            self.play_button.setEnabled(False)
            return

        self.video_label.setText(f"Loading... {camera}")
        self.frames = []
        self.current_frame_idx = 0
        self.current_camera = camera

        # æ ¹æ“šç›¸æ©Ÿé¡å‹é¸æ“‡è§£ç¢¼å™¨
        if camera in ['ecamera', 'fcamera']:
            success = self._load_with_pyav(video_path)
        elif camera == 'qcamera':
            success = self._load_with_opencv(video_path)
        else:
            logger.error(f"Unknown camera type: {camera}")
            return

        if success and self.frames:
            self.timeline_slider.setMaximum(len(self.frames) - 1)
            self.play_button.setEnabled(True)

            # è®€å– EncodeIndex ä»¥å–å¾—æ¯ä¸€å¹€çš„å¯¦éš›æ™‚é–“æˆ³è¨˜
            self._load_frame_timestamps(camera)

            self.display_frame(0)
            logger.info(f"Loaded video: {camera}, {len(self.frames)} frames @ {self.fps} FPS")
        else:
            self.video_label.setText(f"ç„¡æ³•è¼‰å…¥å½±ç‰‡\n{camera}")
            self.play_button.setEnabled(False)

    def _load_with_pyav(self, video_path: str) -> bool:
        """ä½¿ç”¨ PyAV è¼‰å…¥ HEVC å½±ç‰‡ä¸¦é è¼‰æ‰€æœ‰å¹€"""
        if not PYAV_AVAILABLE:
            logger.error("PyAV not available")
            return False

        try:
            container = av.open(video_path)
            video_stream = container.streams.video[0]

            self.fps = float(video_stream.average_rate) if video_stream.average_rate else 20.0

            # é è¼‰æ‰€æœ‰å¹€
            logger.info(f"Loading video frames with PyAV...")
            frame_count = 0
            for frame in container.decode(video=0):
                img = frame.to_ndarray(format='rgb24')
                self.frames.append(img)
                frame_count += 1

                if frame_count % 100 == 0:
                    self.video_label.setText(f"Loading... {frame_count} frames")

            container.close()

            # è¨ºæ–·ï¼šæª¢æŸ¥è¦–é »å…ƒæ•¸æ“šçš„ FPS æ˜¯å¦æ­£ç¢º
            video_metadata_fps = self.fps
            frame_count = len(self.frames)

            # å¦‚æœçŸ¥é“ segment çš„å¯¦éš›æ™‚é•·ï¼Œè¨ˆç®—å¯¦éš› FPS
            if hasattr(self, 'segment_duration_sec') and self.segment_duration_sec and self.segment_duration_sec > 0:
                calculated_fps = frame_count / self.segment_duration_sec
                logger.info(f"ğŸ“¹ Video FPS check:")
                logger.info(f"   Metadata FPS: {video_metadata_fps:.2f}")
                logger.info(f"   Frame count: {frame_count}")
                logger.info(f"   Segment duration: {self.segment_duration_sec:.2f} seconds")
                logger.info(f"   Calculated FPS: {calculated_fps:.2f}")

                # å¦‚æœå·®ç•°è¶…é 10%ï¼Œä½¿ç”¨è¨ˆç®—çš„ FPS
                fps_diff_percent = abs(calculated_fps - video_metadata_fps) / video_metadata_fps * 100
                if fps_diff_percent > 10:
                    logger.warning(f"âš ï¸  Video metadata FPS ({video_metadata_fps:.2f}) differs from actual FPS ({calculated_fps:.2f}) by {fps_diff_percent:.1f}%")
                    logger.warning(f"âš ï¸  Using calculated FPS: {calculated_fps:.2f}")
                    self.fps = calculated_fps

            logger.info(f"PyAV loaded: {len(self.frames)} frames @ {self.fps} FPS")
            return True

        except Exception as e:
            logger.error(f"Failed to load with PyAV: {e}")
            return False

    def _load_with_opencv(self, video_path: str) -> bool:
        """ä½¿ç”¨ OpenCV è¼‰å…¥ H.264/TS å½±ç‰‡ä¸¦é è¼‰æ‰€æœ‰å¹€"""
        if not CV2_AVAILABLE:
            logger.error("OpenCV not available")
            return False

        try:
            cap = cv2.VideoCapture(video_path)

            if not cap.isOpened():
                logger.error("OpenCV failed to open video")
                return False

            self.fps = cap.get(cv2.CAP_PROP_FPS)

            # é è¼‰æ‰€æœ‰å¹€
            logger.info(f"Loading video frames with OpenCV...")
            frame_count = 0
            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                # Convert BGR to RGB
                img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                self.frames.append(img)
                frame_count += 1

                if frame_count % 100 == 0:
                    self.video_label.setText(f"Loading... {frame_count} frames")

            cap.release()

            logger.info(f"OpenCV loaded: {len(self.frames)} frames @ {self.fps} FPS")
            return True

        except Exception as e:
            logger.error(f"Failed to load with OpenCV: {e}")
            return False

    def _load_frame_timestamps(self, camera: str):
        """
        å¾è³‡æ–™åº«è®€å–å½±ç‰‡å¹€æ™‚é–“æˆ³è¨˜

        Args:
            camera: ç›¸æ©Ÿé¡å‹ ('ecamera', 'fcamera', 'qcamera', 'dcamera')
        """
        self.frame_timestamps = []

        # å¦‚æœæ²’æœ‰è³‡æ–™åº«ç®¡ç†å™¨æˆ– segment_idï¼Œè·³é
        if not self.db_manager or not self.segment_id:
            logger.warning("Cannot load frame timestamps: missing db_manager or segment_id, will use calculated time")
            return

        try:
            logger.info(f"Reading frame timestamps for {camera} from database...")

            # å¾è³‡æ–™åº«è®€å–å¹€æ™‚é–“æˆ³è¨˜
            self.frame_timestamps = self.db_manager.get_video_timestamps(self.segment_id, camera)

            logger.info(f"Read {len(self.frame_timestamps)} frame timestamps from database")

            if len(self.frame_timestamps) != len(self.frames):
                logger.warning(f"Database frame count ({len(self.frame_timestamps)}) does not match video frame count ({len(self.frames)})")
                # å¦‚æœæ•¸é‡ä¸ç¬¦ï¼Œæ¸…ç©ºæ™‚é–“æˆ³è¨˜ï¼Œå›é€€åˆ°è¨ˆç®—æ™‚é–“
                self.frame_timestamps = []

        except Exception as e:
            logger.error(f"Failed to read frame timestamps from database: {e}")
            import traceback
            logger.error(traceback.format_exc())
            self.frame_timestamps = []

    def display_frame(self, idx: int):
        """é¡¯ç¤ºæŒ‡å®šå¹€"""
        if idx < 0 or idx >= len(self.frames):
            return

        self.current_frame_idx = idx
        frame = self.frames[idx]

        try:
            height, width, channel = frame.shape
            bytes_per_line = 3 * width
            # è½‰æ› memoryview ç‚º bytes (PyQt6 éœ€è¦)
            frame_bytes = bytes(frame.data)
            q_image = QImage(frame_bytes, width, height, bytes_per_line, QImage.Format.Format_RGB888)

            # ç¸®æ”¾åˆ° label å¤§å°
            pixmap = QPixmap.fromImage(q_image)
            scaled_pixmap = pixmap.scaled(
                self.video_label.size(),
                Qt.AspectRatioMode.KeepAspectRatio,
                Qt.TransformationMode.SmoothTransformation
            )

            self.video_label.setPixmap(scaled_pixmap)

        except Exception as e:
            logger.error(f"Failed to display frame: {e}")

        # æ›´æ–° UI
        self.update_time_display()
        self.timeline_slider.blockSignals(True)
        self.timeline_slider.setValue(idx)
        self.timeline_slider.blockSignals(False)

        # è¨ˆç®—ç•¶å‰æ™‚é–“
        if self.frame_timestamps and idx < len(self.frame_timestamps):
            # ä½¿ç”¨å¾ EncodeIndex è®€å–çš„å¯¦éš›æ™‚é–“æˆ³è¨˜
            current_time_ns = self.frame_timestamps[idx]
            logger.info(f"ğŸ“¹ Frame {idx}: using actual timestamp = {current_time_ns:,}")
        else:
            # å›é€€åˆ°è¨ˆç®—æ™‚é–“ï¼ˆç•¶ EncodeIndex ä¸å¯ç”¨æ™‚ï¼‰
            frame_time_sec = idx / self.fps
            frame_time_ns = int(frame_time_sec * 1e9)
            current_time_ns = self.start_time_ns + frame_time_ns
            logger.info(f"ğŸ“¹ Frame {idx}: using calculated time = start_time_ns({self.start_time_ns:,}) + {frame_time_ns:,} = {current_time_ns:,}")

        # ç™¼é€ä¿¡è™Ÿ
        self.time_changed.emit(current_time_ns)
        self.frame_changed.emit(idx)

    def update_ui_text(self):
        """Update UI text based on current language"""
        if not self.translation_manager:
            return

        t = self.translation_manager.t

        # Update camera label
        self.camera_label.setText(t("Camera:"))

        # Update control buttons
        if self.is_playing:
            self.play_button.setText(t("Pause"))
        else:
            self.play_button.setText(t("Play"))

        self.prev_frame_btn.setText(t("â—€ 1 Frame"))
        self.next_frame_btn.setText(t("1 Frame â–¶"))
        self.back_5s_btn.setText(t("â—€â—€ 5s"))
        self.forward_5s_btn.setText(t("5s â–¶â–¶"))

        # Update time display
        self.update_time_display()

    def update_time_display(self):
        """æ›´æ–°æ™‚é–“é¡¯ç¤º"""
        t = self.translation_manager.t if self.translation_manager else lambda x: x

        # Frame info
        frame_text = t("Frame: 0 / 0").replace("0 / 0", f"{self.current_frame_idx} / {len(self.frames)}")
        self.frame_label.setText(frame_text)

        # è¨ˆç®—ç•¶å‰æ™‚é–“
        if self.frame_timestamps and self.current_frame_idx < len(self.frame_timestamps):
            # ä½¿ç”¨å¯¦éš›æ™‚é–“æˆ³è¨˜
            current_time_ns = self.frame_timestamps[self.current_frame_idx]
        else:
            # ä½¿ç”¨è¨ˆç®—æ™‚é–“
            frame_time_sec = self.current_frame_idx / self.fps
            frame_time_ns = int(frame_time_sec * 1e9)
            current_time_ns = self.start_time_ns + frame_time_ns

        # Real time - å„ªå…ˆä½¿ç”¨ GPS æ¨ç®—çš„æ­£ç¢ºæ™‚é–“
        if self.segment_start_timestamp is not None:
            # ä½¿ç”¨æ­£ç¢ºçš„ segment èµ·å§‹æ™‚é–“ + ç•¶å‰æ’­æ”¾ä½ç½®
            frame_time_sec = self.current_frame_idx / self.fps
            real_timestamp = self.segment_start_timestamp + frame_time_sec
            real_time = datetime.fromtimestamp(real_timestamp)
        else:
            # Fallback: ä½¿ç”¨ wallTimeNanosï¼ˆå¯èƒ½ä¸æº–ç¢ºï¼‰
            real_time_ns = current_time_ns + self.wall_time_offset
            real_time = datetime.fromtimestamp(real_time_ns / 1e9)

        time_text = t("Time: --").replace("--", real_time.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3])
        self.time_label.setText(time_text)

    def toggle_play(self):
        """åˆ‡æ›æ’­æ”¾/æš«åœ"""
        if not self.frames:
            return

        if self.is_playing:
            self.stop()
        else:
            self.play()

    def play(self):
        """é–‹å§‹æ’­æ”¾"""
        if not self.frames:
            return

        self.is_playing = True
        t = self.translation_manager.t if self.translation_manager else lambda x: x
        self.play_button.setText(t("Pause"))
        self.playing_state_changed.emit(True)  # ç™¼é€æ’­æ”¾ç‹€æ…‹æ”¹è®Šä¿¡è™Ÿ

        # è¨ˆç®— timer é–“éš” (æ¯«ç§’)
        interval_ms = int(1000 / self.fps)
        self.timer.start(interval_ms)

        # åŒæ­¥æ¨¡å¼ä¸‹ï¼Œæ‰‹å‹•è§¸ç™¼ç¬¬ä¸€æ¬¡æ™‚é–“æ›´æ–°ä¾†å•Ÿå‹•å¾ªç’°
        if self.sync_mode:
            if self.frame_timestamps and self.current_frame_idx < len(self.frame_timestamps):
                current_time_ns = self.frame_timestamps[self.current_frame_idx]
            else:
                frame_time_sec = self.current_frame_idx / self.fps
                frame_time_ns = int(frame_time_sec * 1e9)
                current_time_ns = self.start_time_ns + frame_time_ns
            self.time_changed.emit(current_time_ns)

    def stop(self):
        """åœæ­¢æ’­æ”¾"""
        self.is_playing = False
        t = self.translation_manager.t if self.translation_manager else lambda x: x
        self.play_button.setText(t("Play"))
        self.playing_state_changed.emit(False)  # ç™¼é€æ’­æ”¾ç‹€æ…‹æ”¹è®Šä¿¡è™Ÿ
        self.timer.stop()

    def on_timer_tick(self):
        """Timer è§¸ç™¼ï¼Œå‰é€²ä¸€å¹€ï¼ˆåƒ…åœ¨éåŒæ­¥æ¨¡å¼ï¼‰"""
        # åŒæ­¥æ¨¡å¼ä¸‹ï¼Œä¸ç”± timer è‡ªå‹•å‰é€²ï¼Œè€Œæ˜¯ç­‰å¾…å¤–éƒ¨ advance_frame() èª¿ç”¨
        if self.sync_mode:
            return

        if self.current_frame_idx < len(self.frames) - 1:
            self.display_frame(self.current_frame_idx + 1)
        else:
            # æ’­æ”¾çµæŸ
            self.stop()

    def advance_frame(self):
        """
        å‰é€²åˆ°ä¸‹ä¸€å¹€ï¼ˆåŒæ­¥æ¨¡å¼ä½¿ç”¨ï¼‰

        Returns:
            bool: æ˜¯å¦æˆåŠŸå‰é€²ï¼ˆFalse è¡¨ç¤ºå·²åˆ°çµå°¾ï¼‰
        """
        if not self.frames or not self.is_playing:
            return False

        if self.current_frame_idx < len(self.frames) - 1:
            self.display_frame(self.current_frame_idx + 1)
            return True
        else:
            # æ’­æ”¾çµæŸ
            self.stop()
            return False

    def step_frame(self, delta: int):
        """å‰é€²/å¾Œé€€æŒ‡å®šå¹€æ•¸"""
        if not self.frames:
            return

        new_frame = self.current_frame_idx + delta
        new_frame = max(0, min(new_frame, len(self.frames) - 1))
        self.display_frame(new_frame)

    def step_time(self, delta_sec: float):
        """å‰é€²/å¾Œé€€æŒ‡å®šç§’æ•¸"""
        if not self.frames:
            return

        delta_frames = int(delta_sec * self.fps)
        self.step_frame(delta_frames)

    def on_slider_changed(self, value: int):
        """æ™‚é–“è»¸æ»‘æ¡¿æ”¹è®Š"""
        if not self.is_playing and self.frames:
            self.display_frame(value)

    def on_camera_changed(self, camera: str):
        """ç›¸æ©Ÿé¸æ“‡æ”¹è®Š"""
        if self.is_playing:
            self.stop()

        logger.info(f"Camera changed to: {camera}")
        self.load_video(camera)
